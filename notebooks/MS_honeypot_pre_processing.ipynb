{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "880af9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from itertools import chain\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.corpora import Dictionary\n",
    "import re\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7cf3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"/Users/amantzio/Desktop/imperial/jupyter_notebook/Microsoft.IoT-Dump1.json\", \"r\",'utf-8-sig') as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0f5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.DataFrame(data)\n",
    "data_pd[\"Commands\"]=[tuple(session) for session in data_pd[\"Commands\"]]\n",
    "data_pd=data_pd.drop_duplicates(subset=\"Commands\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c54525",
   "metadata": {},
   "source": [
    "### Hanyang and Philip's cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25836a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_commands(dat, no_below=2, no_above=1.1):\n",
    "    \"\"\"\n",
    "    This function \n",
    "    1.splits multiple commands in the same line\n",
    "    2. tokenize the commands\n",
    "    3. replace rare commands by rarecommand\n",
    "\n",
    "    :param dat: dataset\n",
    "    :param no_below: Keep tokens which are contained in at least no_below documents.\n",
    "    :param no_above: Keep tokens which are contained in no more than no_above documents \n",
    "    (fraction of total corpus size, not an absolute number).\n",
    "\n",
    "    :return sessins_token_list: tokenized list of sessions of commands\n",
    "    :return dictionary: dictionary generated\n",
    "    \"\"\"\n",
    "    # for commands splitted by ;\n",
    "    sessions = []\n",
    "    for session in dat['Commands']:\n",
    "        sessions.append([]) # to make list of lists\n",
    "        for command in session:\n",
    "            sessions[-1] += command.split('; ')\n",
    "    # tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z0-9_\\.\\-\\*]+')\n",
    "    sessions_list = []\n",
    "    commands_list = []\n",
    "    for session in sessions:\n",
    "        sessions_list.append([])\n",
    "        commands_list.append([])\n",
    "        for command in session:\n",
    "            command_token = tokenizer.tokenize(command)\n",
    "            sessions_list[-1] += [command_token]\n",
    "            commands_list[-1] += command_token\n",
    "    dictionary = Dictionary(commands_list) \n",
    "    dictionary.filter_extremes(no_below, no_above)\n",
    "    # repleace rare commands by rarecommand\n",
    "    dictionary.id2token[-1] = 'rarecommand' ###!!! add a 'rarecommand' token to the corpus and assign a unique value to it -1\n",
    "    ''' -1 value indicates rareword, so when a token appears in sessions\n",
    "    that is not in final dictionary (after filtering) it substitutes the unique value -1 to this token'''\n",
    "    dictionary.token2id['rarecommand'] = -1 \n",
    "    sessions_token_list = []\n",
    "    for session in sessions_list:\n",
    "        sessions_token_list.append([])\n",
    "        commands_token_list = []\n",
    "        for command in session:\n",
    "            idxs = dictionary.doc2idx(command) ###!!! gives to tokens of command the unique values/ids assigned\n",
    "            commands_token_list.append(' '.join([dictionary[idx] for idx in idxs]))\n",
    "        sessions_token_list[-1] += commands_token_list\n",
    "\n",
    "    return sessions_token_list, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d974a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd_clean=clean_commands(data_pd)\n",
    "sessions_list_cleaned=data_pd_clean[0] # list of lists with elements command strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534c074",
   "metadata": {},
   "source": [
    "### Remove empty strings and '.' from sessions list of lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ea1c2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124883/124883 [00:22<00:00, 5645.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Detect position of patterns. patt2 found only in two sessions, remove manually\n",
    "patt=re.compile(r\"^$\")# empty string\n",
    "patt2=re.compile(r\"^\\.$\") # onlyn . in string\n",
    "\n",
    "for i in tqdm.tqdm(range(len(sessions_list_cleaned))):\n",
    "    for j in range(len(sessions_list_cleaned[i])):\n",
    "        if re.search(patt,sessions_list_cleaned[i][j]):\n",
    "            print((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bbb26d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \".\" from list of commands\n",
    "sessions_list_cleaned[77974].remove(\".\")\n",
    "sessions_list_cleaned[44135].remove(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1fa7418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty strings for sessions list of lists\n",
    "for i in range(len(sessions_list_cleaned)):\n",
    "    sessions_list_cleaned[i]=list(filter(None,sessions_list_cleaned[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe5feb7",
   "metadata": {},
   "source": [
    "### Wildcard number for hostnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f7a20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dic={r\"AKEMI\\_[0-9]{4}\":\"AKEMI_num\",\n",
    "           r\"BOT_ID\\s[0-9]{4}\":\"BOT_ID num\",\n",
    "           r\"Ex0\\_[0-9]{4}\":\"Ex0_num\",\n",
    "           r\"HORIZON\\_[0-9]{4}\":\"HORIZON_num\",\n",
    "           r\"Hades\\_[0-9]{4}\":\"Hades_num\",\n",
    "           r\"Hikari\\_[0-9]{4}\":\"Hikari_num\",\n",
    "           r\"Kill\\_[0-9]{4}\":\"Kill_num\",\n",
    "           r\"Mewski\\_[0-9]{4}\":\"Mewski_num\",\n",
    "           r\"SEFA\\_ID\\s[0-9]{4}\":\"SEFA_ID num\",\n",
    "           r\"UNSTABLE\\_[0-9]{4}\":\"UNSTABLE_num\",\n",
    "           r\"WOLF\\_[0-9]{4}\":\"WOLF_num\",\n",
    "           r\"dstrtn\\_[0-9]{4}\":\"dstrtn_num\",\n",
    "           r\"hhh\\_lol\\s[0-9]{4}\":\"hhh_lol num\",\n",
    "           r\"orphic\\_[0-9]{4}\":\"orphic_num\",\n",
    "           r\"shibui\\_[0-9]{4}\":\"shibui_num\",\n",
    "           r\"slumpp\\_[0-9]{4}\":\"slumpp_num\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1a3e079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124883/124883 [04:18<00:00, 482.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(len(sessions_list_cleaned))):\n",
    "    for j in range(len(sessions_list_cleaned[i])):\n",
    "        for key, value in replace_dic.items():\n",
    "            sessions_list_cleaned[i][j] = re.sub(key, value, sessions_list_cleaned[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77cf388",
   "metadata": {},
   "source": [
    "### Fill-in cut commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "65402bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patterns to be replaced\n",
    "patt_list=[\"\\.nippe\"]\n",
    "patt_list1=[\"\\.nippo\"]\n",
    "patt_list2=[\"bin b\",\"bin bu\",\"bin bus\",\"bin busy\",\"bin busyb\",\"bin busybo\"]\n",
    "patt_list3=[\"Ui\",\"Uir\",\"Uiru\"]\n",
    "patt_list4=['bin busybox cat bin busybox w','bin busybox cat bin busybox wh','bin busybox cat bin busybox whi',\n",
    "            'bin busybox cat bin busybox whil','bin busybox cat bin busybox while','bin busybox cat bin busybox while r',\n",
    "            'bin busybox cat bin busybox while rea', 'bin busybox cat bin busybox while read']\n",
    "patt_list5=['bin busybox rm proc sy','bin busybox rm proc sys','bin busybox rm proc sys f',\n",
    "            'bin busybox rm proc sys fs','bin busybox rm proc sys fs b','bin busybox rm proc sys fs bi',\n",
    "            'bin busybox rm proc sys fs bin', 'bin busybox rm proc sys fs binfm','bin busybox rm proc sys fs binfmt', \n",
    "            'bin busybox rm proc sys fs binfmt_','bin busybox rm proc sys fs binfmt_m','bin busybox rm proc sys fs binfmt_mi',\n",
    "            'bin busybox rm proc sys fs binfmt_mis','bin busybox rm proc sys fs binfmt_misc']\n",
    "patt_list6=['bin busybox cat proc sys fs b','bin busybox cat proc sys fs bi','bin busybox cat proc sys fs binf',\n",
    "           'bin busybox cat proc sys fs binfm','bin busybox cat proc sys fs binfmt','bin busybox cat proc sys fs binfmt_',\n",
    "           'bin busybox cat proc sys fs binfmt_m','bin busybox cat proc sys fs binfmt_mi','bin busybox cat proc sys fs binfmt_misc']\n",
    "patt_list7=['sys fs c',\"sys fs cg\",\"sys fs cgro\",\"sys fs cgrou\",\"sys fs cgroup b\",\"sys fs cgroup blki\"]\n",
    "patt_list8=['sys fs f','sys fs fu','sys fs fus','sys fs fuse','sys fs fuse c','sys fs fuse co',\n",
    "            'sys fs fuse con','sys fs fuse conn','sys fs fuse conne','sys fs fuse connec','sys fs fuse connect',\n",
    "           'sys fs fuse connecti','sys fs fuse connectio','sys fs fuse connection']\n",
    "patt_list9=[\"cgroup p\",'cgroup pe','cgroup perf','cgroup perf_','cgroup perf_e',\n",
    "            'cgroup perf_eve','cgroup perf_even']\n",
    "patt_list10=[\"\\.hum\",\"\\.huma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "72375f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patt_all=[patt_list,patt_list1,patt_list2,patt_list3,patt_list4,patt_list5,patt_list6,patt_list7,patt_list8,patt_list9,patt_list10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "43fb627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of strings corresponding to replacements of patterns in patt_all (1st element in replace list corresponds to replacement of patterns in 1st list of patt_all etc..\n",
    "replace_list=['.nipped','.nippon','bin busybox','Uirusu',\n",
    "              'bin busybox cat bin busybox while read i',\n",
    "              'bin busybox rm proc sys fs binfmt_misc .',\n",
    "              'bin busybox cat proc sys fs binfmt_misc .',\n",
    "              'sys fs cgroup blkio',\n",
    "               'sys fs fuse connections','cgroup perf_event',\n",
    "               '.human']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fe058375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124883/124883 [53:22<00:00, 39.00it/s] \n"
     ]
    }
   ],
   "source": [
    "# Replace cut commands with replace_list\n",
    "for i in tqdm.tqdm(range(len(sessions_list_cleaned))):\n",
    "    for j in range(len(sessions_list_cleaned[i])):\n",
    "        for k in range(len(patt_all)):\n",
    "            for l in range(len(patt_all[k])):\n",
    "                patt=re.compile(\"(?<!\\w)\"+patt_all[k][l]+\"(?!\\w)$\")\n",
    "                if re.search(patt,sessions_list_cleaned[i][j]):\n",
    "                    if j==len(sessions_list_cleaned[i])-1: #commands closing a session (that's why commands in patt_all considered as cut commands)\n",
    "                        sessions_list_cleaned[i][j] = re.sub(patt, replace_list[k], sessions_list_cleaned[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabe4c3b",
   "metadata": {},
   "source": [
    "### HEX patt replace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dcd99826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124883/124883 [01:30<00:00, 1377.45it/s]\n"
     ]
    }
   ],
   "source": [
    "replacements = {r\"(?<!\\.)\\bx[a-fA-F0-9]{2}\\b(?!\\.)\": \" HEX \"}\n",
    "#iterate throught corpus\n",
    "for sess in tqdm.tqdm(range(len(sessions_list_cleaned))):\n",
    "    for comm in range(len(sessions_list_cleaned[sess])):\n",
    "        #iterate through replacement patters\n",
    "        for key, value in replacements.items():\n",
    "            text_test = re.sub(key, value, sessions_list_cleaned[sess][comm])\n",
    "            if text_test.startswith(\" HEX \"): \n",
    "                text_test = text_test[1:] \n",
    "            if text_test.endswith(\" HEX \"):\n",
    "                text_test = text_test[:-1]\n",
    "            if text_test.endswith(\" HEX  \"):\n",
    "                text_test = text_test[:-2]    \n",
    "        text_test = re.sub(' +', ' ', text_test) #detect double white spaces and substitute with single space\n",
    "        sessions_list_cleaned[sess][comm] = text_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35278f9",
   "metadata": {},
   "source": [
    "### Format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eade217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124883/124883 [02:24<00:00, 865.10it/s] \n"
     ]
    }
   ],
   "source": [
    "# For each command, Create list of tokens(words) from string command\n",
    "\n",
    "sessions_list_new=[]\n",
    "for sess in tqdm.tqdm(sessions_list_cleaned):\n",
    "    sess_ls=[]\n",
    "    for comm in sess:\n",
    "        sess_ls.append(comm.split(' '))\n",
    "    sessions_list_new.append(sess_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "27828265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of list of lists a single list (to then find the unique tokens)\n",
    "flat_sessions_list_new=[k for i in sessions_list_new for j in i for k in j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c055ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_tokens=set(flat_sessions_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6f3ac91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that maps the unique tokens to unique numbers (Vocabulary)\n",
    "\n",
    "mapping={key:val for val,key in enumerate(uniq_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d65b0fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124883/124883 [04:29<00:00, 463.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Obtain the final form of the data to be used as input in algo\n",
    "# Use mapping to assign the unique values to the tokens in list of sessions\n",
    "\n",
    "final_sessions_list=[]\n",
    "for i in tqdm.tqdm(sessions_list_new):\n",
    "    final_ls=[]\n",
    "    for j in i:\n",
    "        final_ls.append(np.vectorize(mapping.__getitem__)(j))\n",
    "    final_sessions_list.append(final_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "06e4227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124883/124883 [00:45<00:00, 2727.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Three empty string tokens '' identified, drop them from final_sessions_list and from mapping dictionary\n",
    "\n",
    "for i in tqdm.tqdm(range(len(final_sessions_list))):\n",
    "    for j in range(len(final_sessions_list[i])):\n",
    "        if 0 in final_sessions_list[i][j]:\n",
    "            #print(i,j)\n",
    "            '''Exclude empty string '' from list of tokens'''\n",
    "            mask=final_sessions_list[i][j]!=0 \n",
    "            final_sessions_list[i][j]=final_sessions_list[i][j][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "25b8d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del mapping['']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
